#------------------------------------------
# Pull Article Metadata from PubMed:      |
#   (1) publication date                  |
#   (2) MeSH Terms                        |
#   (3) Journal                           |
#   (4) Author Affiliations               |
#   (5) Publication Types                 |
#   (6) Grant Codes*                      |
#         * no longer using - WOS better  |
#------------------------------------------

# Load package for web scraping & cleaning strings
#install.packages("stringr")
#install.packages("rvest")
#install.packages("tidyverse")
#install.packages("xml2")

library(stringr)
library(rvest)
library(tidyverse)
library(xml2)
library(here)
library(haven)

setwd(here())
set.seed(8975)
#--------------------------------------------------------------------------------
# Pull Publication Date, Journal, Publication Type, Journal, MeSH Terms, and Grants
pull_affs = function(id) {
  id_equals = paste0('id=', id)
  if (id_equals != "id=NA") {
    # Form URL using the term
    url = paste0('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id=',
                 id,
                 '&retmode=xml',
                 '&api_key=ae06e6619c472ede6b6d4ac4b5eadecdb209')
    # Query PubMed and save result
    xml = read_xml(url)
    print(id)
    
    gr = xml %>%
      xml_node('GrantList')
    gr = as.character(gr)
    gr = gsub("\n", "", gr)
    
    pt = xml %>%
      xml_node('PublicationTypeList')
    pt = as.character(pt)
    pt = gsub("\n", "", pt)
    
    journal = xml %>%
      xml_node('Journal')
    journal = as.character(journal)
    journal = gsub("\n", "", journal)
    
    date = xml %>%
      xml_node('DateCompleted')
    date = as.character(date)
    date = gsub("\n", "", date)
    
    mesh = xml %>%
      xml_node('MeshHeadingList')
    mesh = as.character(mesh)
    mesh = gsub("\n", "", mesh)
    
    affil = xml %>%
      xml_node('AffiliationInfo')
    affil = as.character(affil)
    affil = gsub("\n", "", affil)
    
    athrs = xml %>%
      xml_find_all(".//AuthorList[@CompleteYN='Y']")
    athrs = as.character(athrs)
    athrs <- ifelse(length(nchar(athrs)) !=0 , athrs, NA) 
    athrs = gsub("\n", "", athrs)
    output = c(date, mesh, journal, affil,athrs, pt, gr)
    Sys.sleep(runif(1,0.3,0.5))
  }
  else {
    output = c("NA", "NA", "NA", "NA", "NA", "NA","NA")
  }
  return(output)
}
################### PULL BASIC SCIENCE METADATA FROM SELECT JOURNALS ###################################
pmid <- read_tsv(file = '../external/basic_select_jrnls_pmids.csv')$pmid
for (i in 1:73) {
  while(TRUE) {
    print(i)
    start <- (i-1)*1000+1
    end <- i*1000
    test <- try(sapply(X = pmid[start:end], FUN = pull_affs))
    if(!is(test, 'try-error')) break
  }
  info = test
  master = data.frame(pmid = pmid[start:end], date = info[1,], mesh = info[2,],
                      journal=info[3,], affil=info[4,], athrs = info[5,], pt = info[6,], gr = info[7,])
  file_name = paste("../output/metadata/basic_select_jrnl_",start,"_", end,".csv", sep="")
  write_csv(master, file = file_name)
}

################### PULL TRANSLATIONAL SCIENCE METADATA FROM SELECT JOURNALS ###################################
pmid <- read_tsv(file = '../external/trans_select_jrnls_pmids.csv')$pmid
for (i in 1:159) {
  while(TRUE) {
    print(i)
    start <- (i-1)*1000+1
    end <- i*1000
    test <- try(sapply(X = pmid[start:end], FUN = pull_affs))
    if(!is(test, 'try-error')) break
  }
  info = test
  master = data.frame(pmid = pmid[start:end], date = info[1,], mesh = info[2,],
                      journal=info[3,], affil=info[4,], athrs = info[5,], pt = info[6,], gr = info[7,])
  file_name = paste("../output/metadata/trans_select_jrnl_",start,"_", end,".csv", sep="")
  write_csv(master, file = file_name)
}
################### PULL 5% 2019 BASIC SCIENCE METADATA ###################################
queries_sub <- read_dta(file = '../external/BTC_pmids.dta')
queries <- queries_sub %>% 
  filter(btc == "basic",
         year>=1988)

PMIDs <- queries %>% select(pmid, year) %>% as.data.frame() %>% 
  group_by(year) %>% 
  slice_sample(prop=0.05) 
# PMIDdf.rand_samp <- PMIDs[sample(nrow(PMIDs), size = round(nrow(PMIDs)*0.10, digits = 0), replace = FALSE), ]
pmid <- PMIDs$pmid

for (i in 1:321) {
  while(TRUE) {
    print(i)
    start <- (i-1)*1000+1
    end <- i*1000
    test <- try(sapply(X = pmid[start:end], FUN = pull_affs))
    if(!is(test, 'try-error')) break
  }
  info = test
  master = data.frame(pmid = pmid[start:end], date = info[1,], mesh = info[2,],
                      journal=info[3,], affil=info[4,], athrs = info[5,], pt = info[6,], gr = info[7,])
  file_name = paste("../output/metadata/basic_5pt_",start,"_", end,".csv", sep="")
  write_csv(master, file = file_name)
}
